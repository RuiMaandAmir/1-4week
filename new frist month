总体说明
时长：30天，每天3小时，共90小时。

目标：
巩固数学基础（线性代数、微积分）。

掌握Python基础，学习C++入门。

理解机器学习核心算法（线性回归、逻辑回归、SVM、决策树）。

完成小型机器学习项目（如Kaggle分类任务）。

每日结构：
0:00-1:00 理论学习：通过B站、网易云课堂等免费资源，学习指定章节，记录知识点。

1:00-2:00 习题练习：完成数学推导或编程任务（Khan Academy、LeetCode、Coursera）。

2:00-3:00 实践任务：基于Kaggle、天池数据集或GitHub代码，完成项目或复现。

资源：B站、网易云课堂、Khan Academy、Coursera（免费部分）、Kaggle、天池、Hugging Face、GitHub、arXiv、菜鸟教程。

强度策略：整合数学与编程（边学边用），每天实践小型任务，每周阅读2-3篇arXiv论文摘要。

详细逐日计划：第1-30天
第1天：线性代数基础与Python环境搭建
0:00-1:00 理论学习
资源：B站《3Blue1Brown线性代数》第1集（链接)

内容：向量定义、加法、标量乘法、线性组合（约30分钟）

知识点总结：向量表示多维空间点，线性组合是向量加权和，用于线性方程解。公式：v = au1 + bu2。

任务：记笔记，画2个向量加法示例（手绘或用工具）。

1:00-2:00 习题练习
资源：Khan Academy线性代数练习（链接)

内容：完成5道向量加法和标量乘法题（如[2,3]+[1,-1]，2*[1,2]）

任务：手写推导，验证答案，记录错误点。

2:00-3:00 实践任务
资源：菜鸟教程Python安装指南（链接），Kaggle Python入门笔记本（链接)

内容：安装Python 3.9、Anaconda，配置Jupyter Notebook；运行Kaggle Python基础代码

任务：创建2x3 NumPy数组，计算数组加法，保存Notebook

输出：上传代码至GitHub个人仓库（GitHub)，记录运行结果

第2天：矩阵基础与Python数据处理
0:00-1:00 理论学习
资源：B站《3Blue1Brown线性代数》第3集（链接)

内容：矩阵定义、矩阵乘法、转置（约30分钟）

知识点总结：矩阵表示线性变换，矩阵乘法是变换组合，(AB)^T = B^T A^T。

任务：记笔记，写2x2矩阵乘法公式。

1:00-2:00 习题练习
资源：Khan Academy矩阵练习（链接)

内容：完成5道矩阵加法和乘法题（如[[1,2],[3,4]] * [[0,1],[1,0]]）

任务：手写推导，验证结果。

2:00-3:00 实践 task
资源：Kaggle Pandas教程（链接)

内容：用Pandas加载CSV文件，处理缺失值

任务：加载Kaggle Titanic数据集，计算年龄均值，填补缺失年龄

输出：保存Notebook，记录处理后数据集统计信息

第3天：微积分基础与Python可视化
0:00-1:00 理论学习
资源：B站《微积分》（同济大学）第1讲（链接)

content：导数定义、基本求导法则（约40分钟）

知识点总结：导数表示函数变化率，d/dx(x^n) = nx^(n-1)，链式法则：d/dx(f(g(x))) = f'(g(x))g'(x)。

任务：记笔记，写3个导数公式。

1:00-2:00 习题练习
资源：Khan Academy微积分练习（链接)

内容：完成5道简单求导题（如d/dx(3x^2 + 2x)）

任务：手写推导，记录错误点。

2:00-3:00 实践任务
资源：Kaggle Matplotlib教程（链接)

内容：用Matplotlib绘制Titanic数据集年龄分布

任务：绘制直方图，标注均值和中位数

输出：保存图表PNG，上传GitHub

第4天：线性回归理论与Python实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第1讲（链接)

内容：线性回归模型、损失函数（约40分钟）

知识点总结：线性回归预测连续值，损失函数为均方误差：L = Σ(y - ŷ)^2/n，优化目标是最小化L。

任务：记笔记，写MSE公式。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 1作业（免费审计，链接)

内容：完成5道MSE计算题

任务：手写MSE推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle线性回归示例（链接)

内容：用scikit-learn实现房价预测

任务：加载Kaggle房价数据集，训练线性回归模型，输出R^2分数

输出：保存模型代码，记录R^2（目标>0.7）

第5天：梯度下降与NumPy实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第2讲（链接)

内容：梯度下降原理、学习率（约40分钟）

知识点总结：梯度下降通过迭代更新参数θ = θ - η*∇L，η为学习率，控制步长。

任务：记笔记，画梯度下降迭代示意图。

1:00-2:00 习题练习
资源：Khan Academy梯度练习（链接)

内容：完成5道简单梯度计算题（如∇(x^2 + y^2)）

任务：手写推导，验证结果。

2:00-3:00 实践任务
资源：GitHub线性回归代码（链接)

内容：用NumPy实现梯度下降线性回归

任务：生成随机数据集，手写梯度下降，输出损失曲线

输出：保存代码，记录最终损失

第6天：C++基础与矩阵运算
0:00-1:00 理论学习
资源：菜鸟教程C++基础（链接)

内容：C++变量、数组、循环（约30分钟）

知识点总结：C++数组存储矩阵，for循环实现矩阵运算，语法更严格。

任务：记笔记，写简单for循环示例。

1:00-2:00 习题练习
资源：LeetCode C++入门题（链接)

内容：完成3道数组操作题（如数组求和）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++矩阵运算代码（链接)

内容：用C++实现2x2矩阵乘法

任务：编写矩阵类，测试乘法功能

输出：保存代码，记录运行结果

第7天：逻辑回归与Python实践
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第3讲（链接)

内容：逻辑回归、Sigmoid函数（约40分钟）

知识点总结：逻辑回归用于二分类，Sigmoid：σ(z) = 1/(1+e^-z)，交叉熵损失衡量误差。

任务：记笔记，写Sigmoid公式。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 2作业（链接)

内容：完成5道逻辑回归损失计算题

任务：手写交叉熵推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle Titanic数据集（链接)

内容：用scikit-learn实现Titanic生存预测

任务：预处理数据，训练逻辑回归模型，输出准确率

输出：保存模型代码，记录准确率（目标>0.75）

第8天：概率基础与Python统计
0:00-1:00 理论学习
资源：网易云课堂《概率统计》（清华大学）第1讲（链接)

内容：概率定义、条件概率（约40分钟）

知识点总结：P(A|B) = P(A∩B)/P(B)，贝叶斯公式：P(A|B) = P(B|A)P(A)/P(B)。

任务：记笔记，写贝叶斯公式。

1:00-2:00 习题练习
资源：Khan Academy概率练习（链接)

内容：完成5道条件概率题

任务：手写推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle Pandas统计分析（链接)

内容：用Pandas计算Titanic数据集概率分布

任务：计算生存率、性别分布，绘制饼图

输出：保存图表，上传GitHub

第9天：SVM理论与Python实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第5讲（链接)

内容：支持向量机、最大间隔（约40分钟）

知识点总结：SVM寻找最大间隔超平面，核函数处理非线性数据。

任务：记笔记，画SVM超平面示意图。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 6作业（链接)

内容：完成5道SVM分类题

任务：手写拉格朗日对偶推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle SVM示例（链接)

内容：用scikit-learn实现Titanic分类

任务：训练SVM模型（线性核），输出准确率

Output：保存代码，记录准确率（目标>0.78）

第10天：C++指针与数组操作
0:00-1:00 理论学习
资源：菜鸟教程C++指针（链接)

Content：指针定义、数组操作（约30分钟）

知识点总结：指针存储内存地址，int* p指向整数，数组名是首地址。

任务：记笔记，写指针声明示例。

1:00-2:00 习题练习
资源：LeetCode C++指针题（链接)

Content：完成3道指针操作题（如数组反转）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++数组代码（链接)

Content：用C++实现动态数组求和

任务：编写函数，测试10个随机数

Output：保存代码，记录运行结果

第11天：决策树理论与Python实践
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第6讲（链接)

Content：决策树、熵、信息增益（约40分钟）

知识点总结：决策树通过信息增益分裂节点，熵：H = -Σp*log(p)。

任务：记笔记，写熵公式。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 5作业（链接)

Content：完成5道熵计算题

任务：手写信息增益推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle决策树示例（链接)

Content：用scikit-learn实现Titanic分类

任务：训练决策树模型，输出准确率

Output：保存代码，记录准确率（目标>0.80）

第12天：随机森林与Python集成
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第7讲（链接)

Content：随机森林、Bagging（约40分钟）

知识点总结：随机森林集成多棵决策树，Bagging降低方差。

任务：记笔记，画Bagging示意图。

1:00-2:00 习题练习
资源：Kaggle随机森林练习（链接)

Content：完成5道特征重要性分析题

任务：手写特征选择过程，验证答案。

2:00-3:00 实践任务
资源：Kaggle房价数据集（链接)

Content：用scikit-learn实现房价预测

任务：训练随机森林模型，输出R^2分数

Output：保存代码，记录R^2（目标>0.85）

第13天：微积分进阶与梯度应用
0:00-1:00 理论学习
资源：B站《微积分》（同济大学）第3讲（链接)

Content：偏导数、梯度（约40分钟）

知识点总结：偏导数∂f/∂x表示单变量变化率，梯度∇f指向最大增长方向。

任务：记笔记，写梯度公式。

1:00-2:00 习题练习
资源：Khan Academy偏导数练习（链接)

Content：完成5道偏导数题（如∂/∂x(x^2y)）

任务：手写推导，验证结果。

2:00-3:00 实践任务
资源：GitHub梯度下降代码（链接)

Content：用NumPy实现多变量梯度下降

任务：优化简单二次函数，绘制损失曲线

Output：保存代码，记录曲线PNG

第14天：C++类与矩阵类实现
0:00-1:00 理论学习
资源：菜鸟教程C++类（链接)

Content：类定义、成员函数（约30分钟）

知识点总结：类封装数据和方法，public/private控制访问。

任务：记笔记，写简单类示例。

1:00-2:00 习题练习
资源：LeetCode C++类题（链接)

Content：完成3道类操作题（如链表节点）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++矩阵类（链接)

Content：用C++实现矩阵类（加法、乘法）

任务：测试2x2矩阵运算

Output：保存代码，记录运行结果

第15天：Kaggle项目整合
0:00-1:00 理论学习
资源：Kaggle机器学习入门教程（链接)

Content：特征工程、模型评估（约30分钟）

知识点总结：特征工程提取有用信息，交叉验证评估模型稳定性。

任务：记笔记，写交叉验证公式。

1:00-2:00 习题练习
资源：Kaggle特征工程练习（链接)

Content：完成5道特征提取题

任务：手写特征处理代码，验证结果。

2:00-3:00 实践任务
资源：Kaggle Titanic数据集（链接)

Content：整合逻辑回归、SVM、决策树

任务：训练3种模型，比较准确率

Output：保存代码，记录最佳模型（目标>0.82）

第16天：概率分布与Python实现
0:00-1:00 理论学习
资源：网易云课堂《概率统计》第2讲（链接)

Content：正态分布、期望、方差（约40分钟）

知识点总结：正态分布N(μ,σ^2)，E(X) = μ，Var(X) = σ^2。

任务：记笔记，写正态分布公式。

1:00-2:00 习题练习
资源：Khan Academy正态分布练习（链接)

Content：完成5道期望和方差题

任务：手写推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle正态分布分析（链接)

Content：用SciPy拟合Titanic年龄分布

任务：绘制拟合曲线，输出μ和σ

Output：保存图表，上传GitHub

第17天：神经网络基础与Python实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第8讲（链接)

Content：神经网络结构、前向传播（约40分钟）

知识点总结：神经网络由输入层、隐藏层、输出层组成，激活函数增加非线性。

任务：记笔记，画简单神经网络结构图。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 4作业（链接)

Content：完成5道前向传播计算题

任务：手写激活函数推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle神经网络示例（链接)

Content：用scikit-learn实现Titanic分类

任务：训练MLP模型，输出准确率

Output：保存代码，记录准确率（目标>0.80）

第18天：C++函数与神经元实现
0:00-1:00 理论学习
资源：菜鸟教程C++函数（链接)

Content：函数定义、参数传递（约30分钟）

知识点总结：函数封装逻辑，值传递和引用传递影响性能。

任务：记笔记，写函数声明示例。

1:00-2:00 习题练习
资源：LeetCode C++函数题（链接)

Content：完成3道函数实现题（如矩阵转置）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++神经元代码（链接)

Content：用C++实现简单神经元（Sigmoid）

任务：测试单神经元输出

Output：保存代码，记录运行结果

第19天：反向传播与Python实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第9讲（链接)

Content：反向传播、链式法则（约40分钟）

知识点总结：反向传播通过链式法则计算梯度，更新权重。

任务：记笔记，写反向传播公式。

1:00-2:00 习题练习
资源：Coursera吴恩达《Machine Learning》Week 5作业（链接)

Content：完成5道反向传播计算题

任务：手写梯度推导，验证答案。

2:00-3:00 实践任务
资源：GitHub反向传播代码（链接)

Content：用NumPy实现简单神经网络

任务：训练XOR问题，输出损失曲线

Output：保存代码，记录曲线PNG

第20天：Kaggle房价预测整合
0:00-1:00 理论学习
资源：Kaggle机器学习进阶教程（链接)

Content：模型调参、过拟合（约30分钟）

知识点总结：正则化（如L2）防止过拟合，网格搜索优化超参数。

任务：记笔记，写L2正则化公式。

1:00-2:00 习题练习
资源：Kaggle调参练习（链接)

Content：完成5道超参数选择题

任务：手写网格搜索伪代码，验证答案。

2:00-3:00 实践任务
资源：Kaggle房价数据集（链接)

Content：整合线性回归、随机森林、神经网络

任务：训练3种模型，比较R^2分数

Output：保存代码，记录最佳模型（目标>0.88）

第21天：概率进阶与贝叶斯
0:00-1:00 理论学习
资源：网易云课堂《概率统计》第3讲（链接)

Content：贝叶斯推断、似然函数（约40分钟）

知识点总结：贝叶斯推断更新后验概率，P(θ|D) ∝ P(D|θ)P(θ)。

任务：记笔记，写似然函数示例。

1:00-2:00 习题练习
资源：Khan Academy贝叶斯练习（链接)

Content：完成5道贝叶斯计算题

任务：手写后验概率推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle贝叶斯分析（链接)

Content：用PyMC3实现简单贝叶斯模型

任务：拟合Titanic生存概率，输出后验分布

Output：保存图表，上传GitHub

第22天：C++动态内存与矩阵运算
0:00-1:00 理论学习
资源：菜鸟教程C++动态内存（链接)

Content：new/delete、动态数组（约30分钟）

知识点总结：new分配内存，delete释放，防止内存泄漏。

任务：记笔记，写动态数组示例。

1:00-2:00 习题练习
资源：LeetCode C++动态内存题（链接)

Content：完成3道动态数组题（如矩阵初始化）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++矩阵运算（链接)

Content：用C++实现动态矩阵乘法

任务：测试3x3矩阵运算

Output：保存代码，记录运行结果

第23天：集成学习与Python实践
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第10讲（链接)

Content：Boosting、AdaBoost（约40分钟）

知识点总结：Boosting通过加权样本提升弱分类器，AdaBoost调整样本权重。

任务：记笔记，写AdaBoost伪代码。

1:00-2:00 习题练习
资源：Kaggle Boosting练习（链接)

Content：完成5道权重更新题

任务：手写权重计算，验证答案。

2:00-3:00 实践任务
资源：Kaggle Titanic数据集（链接)

Content：用scikit-learn实现AdaBoost分类

任务：训练AdaBoost模型，输出准确率

Output：保存代码，记录准确率（目标>0.82）

第24天：数学优化与Python实现
0:00-1:00 理论学习
资源：B站《微积分》（同济大学）第4讲（链接)

Content：凸优化、拉格朗日乘子（约40分钟）

知识点总结：凸优化保证全局最优，拉格朗日乘子解决约束优化。

任务：记笔记，写拉格朗日公式。

1:00-2:00 习题练习
资源：Khan Academy优化练习（链接)

Content：完成5道拉格朗日乘子题

任务：手写推导，验证结果。

2:00-3:00 实践任务
资源：GitHub优化代码（链接)

Content：用SciPy实现约束优化

任务：优化简单二次函数，输出最优解

Output：保存代码，记录结果

第25天：天池项目实践
0:00-1:00 理论学习
资源：天池机器学习教程（链接)

Content：数据预处理、模型选择（约30分钟）

知识点总结：数据清洗确保模型质量，模型选择需权衡偏差和方差。

任务：记笔记，写数据清洗步骤。

1:00-2:00 习题练习
资源：天池数据预处理练习（链接)

Content：完成5道数据清洗题

任务：手写预处理代码，验证结果。

2:00-3:00 实践任务
资源：天池入门竞赛（链接)

Content：参与分类任务（如二手车价格预测）

任务：训练随机森林模型，提交结果

Output：保存代码，记录排名

第26天：C++模板与矩阵库
0:00-1:00 理论学习
资源：菜鸟教程C++模板（链接)

Content：函数模板、类模板（约30分钟）

知识点总结：模板实现泛型编程，提高代码复用性。

任务：记笔记，写模板函数示例。

1:00-2:00 习题练习
资源：LeetCode C++模板题（链接)

Content：完成3道模板实现题（如泛型数组）

任务：用C++编写代码，验证结果。

2:00-3:00 实践任务
资源：GitHub C++矩阵库（链接)

Content：用C++模板实现矩阵类

任务：测试泛型矩阵加法

Output：保存代码，记录运行结果

第27天：聚类算法与Python实践
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第11讲（链接)

Content：K均值聚类、层次聚类（约40分钟）

知识点总结：K均值最小化簇内方差，层次聚类构建树状结构。

任务：记笔记，写K均值伪代码。

1:00-2:00 习题练习
资源：Kaggle聚类练习（链接)

Content：完成5道K均值计算题

任务：手写簇中心更新，验证答案。

2:00-3:00 实践任务
资源：Kaggle客户分割数据集（链接)

Content：用scikit-learn实现K均值聚类

任务：聚类客户数据，输出簇分布

Output：保存代码，记录簇可视化

第28天：降维算法与Python实现
0:00-1:00 理论学习
资源：B站李宏毅《机器学习2023》第12讲（链接)

Content：主成分分析（PCA）、特征值分解（约40分钟）

知识点总结：PCA通过特征值分解降维，保留最大方差方向。

任务：记笔记，写PCA公式。

1:00-2:00 习题练习
资源：Kaggle PCA练习（链接)

Content：完成5道PCA计算题

任务：手写协方差矩阵推导，验证答案。

2:00-3:00 实践任务
资源：Kaggle Titanic数据集（链接)

Content：用scikit-learn实现PCA降维

任务：降维后训练逻辑回归，输出准确率

Output：保存代码，记录准确率（目标>0.78）

第29天：arXiv论文阅读与复现
0:00-1:00 理论学习
资源：arXiv机器学习论文（链接)

Content：阅读1篇线性回归相关论文摘要及引言（约30分钟）

知识点总结：记录论文提出的优化方法或正则化技巧。

任务：记笔记，写论文核心方法总结。

1:00-2:00 习题练习
资源：GitHub论文代码（链接)

Content：分析论文代码结构

任务：写代码注释，理解算法实现。

2:00-3:00 实践任务
资源：Kaggle房价数据集（链接)

Content：复现论文中的正则化方法

任务：实现Lasso回归，输出R^2分数

Output：保存代码，记录R^2（目标>0.80）

第30天：第一月总结与项目优化
0:00-1:00 理论学习
资源：Kaggle机器学习总结教程（链接)

Content：复习模型评估指标（准确率、F1、R^2）（约30分钟）

知识点总结：F1平衡精确率和召回率，R^2衡量回归拟合度。

任务：记笔记，写F1公式。

1:00-2:00 习题练习
资源：Kaggle评估练习（链接)

Content：完成5道评估指标计算题

任务：手写F1计算，验证答案。

2:00-3:00 实践任务
资源：天池入门竞赛（链接)

Content：优化第25天竞赛模型

任务：调整超参数，提交改进结果

Output：保存代码，记录排名提升

所有资源链接
以下是第一个月使用的所有免费资源链接，确保国内可访问：
B站课程：
3Blue1Brown线性代数：https://www.bilibili.com/video/BV1ys411472E

同济大学微积分：https://www.bilibili.com/video/BV1Zb411q7iY

李宏毅机器学习2023：https://www.bilibili.com/video/BV1vM411H7Tj

网易云课堂：
概率统计（清华大学）：https://www.163.com/course/（需搜索“概率统计”）

Khan Academy：
线性代数：https://www.khanacademy.org/math/linear-algebra

微积分：https://www.khanacademy.org/math/calculus-1

概率统计：https://www.khanacademy.org/math/statistics-probability

优化与偏导数：https://www.khanacademy.org/math/multivariable-calculus

Coursera（免费审计）：
吴恩达Machine Learning：https://www.coursera.org/learn/machine-learning

Kaggle：
Python入门：https://www.kaggle.com/learn/python

Pandas教程：https://www.kaggle.com/learn/pandas

Matplotlib教程：https://www.kaggle.com/learn/data-visualization

机器学习入门：https://www.kaggle.com/learn/intro-to-machine-learning

机器学习进阶：https://www.kaggle.com/learn/intermediate-machine-learning

特征工程：https://www.kaggle.com/learn/feature-engineering

聚类：https://www.kaggle.com/learn/clustering

降维：https://www.kaggle.com/learn/dimensionality-reduction

统计分析：https://www.kaggle.com/learn/stats

贝叶斯方法：https://www.kaggle.com/learn/bayesian-methods

Titanic数据集：https://www.kaggle.com/competitions/titanic

房价数据集：https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques

客户分割数据集：https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python

天池：
机器学习教程：https://tianchi.aliyun.com/learn

入门竞赛：https://tianchi.aliyun.com/competition

菜鸟教程：
Python安装：https://www.runoob.com/python3/python3-install.html

C++基础：https://www.runoob.com/cplusplus/cpp-tutorial.html

C++指针：https://www.runoob.com/cplusplus/cpp-pointers.html

C++类：https://www.runoob.com/cplusplus/cpp-classes-objects.html

C++函数：https://www.runoob.com/cplusplus/cpp-functions.html

C++动态内存：https://www.runoob.com/cplusplus/cpp-dynamic-memory.html

C++模板：https://www.runoob.com/cplusplus/cpp-templates.html

GitHub：
线性回归代码：https://github.com/topics/linear-regression

梯度下降代码：https://github.com/topics/gradient-descent

反向传播代码：https://github.com/topics/backpropagation

优化代码：https://github.com/topics/optimization

C++矩阵运算：https://github.com/topics/matrix

C++神经元：https://github.com/topics/neural-network

个人仓库：https://github.com/

arXiv：
机器学习论文：https://arxiv.org/list/cs.LG/recent

LeetCode：
C++题目：https://leetcode.cn/problems/


